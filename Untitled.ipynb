{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed8d3712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set after removing duplicates: (29530, 4)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train.drop_duplicates(subset=['tweet'], keep='last', inplace=True)\n",
    "df_train.reset_index(inplace=True)\n",
    "print(\"Shape of Train set after removing duplicates:\", df_train.shape)\n",
    "df_offensive =pd.read_csv(\"labeled_data.csv\")\n",
    "df_offensive[\"class\"].replace({0: 1}, inplace=True)\n",
    "df_offensive[\"class\"].replace({2: 0}, inplace=True)\n",
    "df_offensive.drop(['Unnamed: 0','count','hate_speech','offensive_language','neither'],axis=1,inplace=True)\n",
    "df_offensive.rename(columns ={'class':'label'}, inplace = True)\n",
    "df_train_final = pd.concat([df_train,df_offensive])\n",
    "df_train_final.drop(['id'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "922e82f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54313 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  label                                              tweet\n",
       "0        0.0      0   @user when a father is dysfunctional and is s...\n",
       "1        1.0      0  @user @user thanks for #lyft credit i can't us...\n",
       "2        2.0      0                                bihday your majesty\n",
       "3        4.0      0             factsguide: society now    #motivation\n",
       "4        5.0      0  [2/2] huge fan fare and big talking before the...\n",
       "...      ...    ...                                                ...\n",
       "24778    NaN      1  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "24779    NaN      0  you've gone and broke the wrong heart baby, an...\n",
       "24780    NaN      1  young buck wanna eat!!.. dat nigguh like I ain...\n",
       "24781    NaN      1              youu got wild bitches tellin you lies\n",
       "24782    NaN      0  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "\n",
       "[54313 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5d921c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configs\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "SENTENCE_LENGTH = 256\n",
    "GLOVE_FILE = f'GLOVE_FILE/glove.twitter.27B.{EMBEDDING_DIM}d.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ba1c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = {}\n",
    "\n",
    "with open(GLOVE_FILE, 'r', encoding='utf-8') as file:\n",
    "    for every_line in file:\n",
    "        values = line.strip().split()\n",
    "        w = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings[w] = vectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a3a0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def normalize_word(text):\n",
    "    # Remove white space, cast to lowercase, \n",
    "    # remove punctuation and numbers\n",
    "    text = text.lower()\n",
    "    text = text.translate(translator)\n",
    "    text = text.strip(' ')\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "#     text = ps.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "612542b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21897273  0.1726903  -0.05617734  0.06307698  0.00960728 -0.23460951\n",
      " -0.16731708 -0.2561423   0.12990884 -0.34179983 -0.0741225   0.00533566\n",
      "  0.7090389  -0.11390167  0.10614155  0.0918671   0.15881167  0.03158503\n",
      "  0.22414173  0.2038661   0.05305528  0.04961339  0.11807609 -0.10199956\n",
      " -0.18345638  0.56560236  0.07183184  0.04322483 -0.3944268   0.06828406\n",
      "  0.3954251   0.08794737  0.41605267 -0.27821    -0.5106839  -0.1644394\n",
      "  0.09734457  0.02233139  0.19346268  0.15909804  0.8865828  -0.01498249\n",
      "  0.10210968 -0.1295932  -0.32836685  0.13014711 -0.02061143  0.05735637\n",
      "  0.14008194  0.22588335]\n"
     ]
    }
   ],
   "source": [
    "# Get number of vectors and hidden dim\n",
    "with open(GLOVE_FILE, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        pass\n",
    "n_vec = i + 1\n",
    "hidden_dim = len(line.split(' ')) - 1\n",
    "\n",
    "vecs = np.zeros((n_vec, hidden_dim), dtype=np.float32)\n",
    "\n",
    "with open(GLOVE_FILE, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        vecs[i] = np.array([float(n) for n in line.split(' ')[1:]], dtype=np.float32)\n",
    "\n",
    "average_vec = np.mean(vecs, axis=0)\n",
    "print(average_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1c98b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "WARN = True\n",
    "def encode_sentence(sentence, embeddings, sentence_length=SENTENCE_LENGTH):\n",
    "    encoded_sentence = []\n",
    "    words = list(map(lambda w: normalize_word(w), sentence.split(' ')))\n",
    "    for word in words:\n",
    "        if word == '':\n",
    "            continue\n",
    "        if len(encoded_sentence) >= sentence_length:\n",
    "            break\n",
    "        if word in embeddings:\n",
    "            word_embedding = embeddings[word]\n",
    "        else:\n",
    "            word_embedding = average_vec\n",
    "#             continue\n",
    "    \n",
    "        encoded_sentence.append(word_embedding)\n",
    "        \n",
    "    # Zero Pad embeddings to sentence_length for LSTM batch training\n",
    "    while len(encoded_sentence) < sentence_length:\n",
    "        encoded_sentence.append(np.zeros((EMBEDDING_DIM)))\n",
    "    return np.array(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6d2b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words('english')\n",
    "stm = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "def text_cleaner(input_text):\n",
    "    input_text = re.sub(r'@[A-Za-z0-9_]+','',str(input_text))    # Removing @mentions\n",
    "    input_text = re.sub(r'#','',str(input_text))                 # Removing #tag symbol\n",
    "    input_text = re.sub(r'RT[\\s]+',' ',input_text)          # Remvoing RT\n",
    "    input_text = re.sub(r'\\n','',input_text) \n",
    "    input_text = re.sub(r',','',input_text) \n",
    "    input_text = re.sub(r'.[.]+','',input_text) \n",
    "    input_text = re.sub(r'\\w+:\\/\\/\\S+','',input_text) \n",
    "    input_text = re.sub(r'https?:\\/\\/\\S+','',input_text)    # Removing hyperlinks\n",
    "    input_text = re.sub(r'/',' ',input_text)\n",
    "    input_text = re.sub(r'-',' ',input_text)\n",
    "    input_text = re.sub(r'_',' ',input_text)\n",
    "    input_text = re.sub(r'!','',input_text)\n",
    "    input_text = re.sub(r':',' ',input_text)\n",
    "    input_text = re.sub(r'$','',input_text)\n",
    "    input_text = re.sub(r'%','',input_text)\n",
    "    input_text = re.sub(r'^','',input_text)\n",
    "    input_text = re.sub(r'&','',input_text)\n",
    "    input_text = re.sub(r'=',' ',input_text)\n",
    "    input_text = re.sub(r' +',' ',input_text) \n",
    "    input_text = re.sub('\\[.*?\\]', '', input_text)\n",
    "    input_text = re.sub('https?://\\S+|www\\.\\S+', '', input_text)\n",
    "    input_text = re.sub('<.*?>+', '', input_text)\n",
    "    input_text = re.sub('[%s]' % re.escape(string.punctuation), '', input_text)\n",
    "    input_text = re.sub('\\n', '', input_text)\n",
    "    input_text = re.sub('[0-9]+', '', input_text) # removing numbers\n",
    "    input_text = str(input_text).lower() # converting to lowercase \n",
    "    input_text = str(input_text).strip()  # Removing all the leading and trailing whitespaces present in the input data \n",
    "    input_text = [word for word in input_text.split(' ') if word not in stop_word]\n",
    "    input_text=\" \".join(input_text)\n",
    "    input_text = [stm.stem(word) for word in input_text.split(' ')]\n",
    "    input_text=\" \".join(input_text)\n",
    "    return input_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8743e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_X(dfx, embeddings):\n",
    "    encoded_df = []\n",
    "    for x in dfx.values:\n",
    "        sentence_embedding = encode_sentence(x, embeddings)\n",
    "        encoded_df.append(sentence_embedding)\n",
    "    np.concatenate(encoded_df, axis=0)\n",
    "    return np.array(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8374c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train_final['tweet'] \n",
    "y = df_train_final['label'] \n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, train_size = 0.8, random_state = 3) \n",
    "\n",
    "X_train = encode_X(X_train, embeddings)\n",
    "X_test = encode_X(X_test, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69be40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final['tweet']=df_train_final['tweet'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26341d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "loaded_model = pickle.load(open('finalized_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc479573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54313 entries, 0 to 24782\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   index   29530 non-null  float64\n",
      " 1   label   54313 non-null  int64  \n",
      " 2   tweet   54313 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X = df_train_final['tweet'].astype(str)  # Converting to string, because vectorizer does'nt accept list.\n",
    "y = df_train_final['label'].astype(str)  # Converting to string, because vectorizer does'nt accept list.\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, train_size = 0.8, random_state = 3) \n",
    "df_train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97815417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: ['piec shi hate yo alright']\n",
      "pred ['1']\n",
      "Text falls under hate and abusive category\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "test = 'You are a piece of shit. I hate you. Are you alright?'\n",
    "test=[text_cleaner(test)]\n",
    "print('Input text:', test)\n",
    "test_vect = vectoriser.transform(test)\n",
    "pred = loaded_model.predict(test_vect)\n",
    "print(\"pred\", pred)\n",
    "if (pred=='1'):\n",
    "    print('Text falls under hate and abusive category')\n",
    "else:\n",
    "    print('Text is safe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fec6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
